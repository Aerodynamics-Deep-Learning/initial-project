{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575710c2",
   "metadata": {},
   "source": [
    "This training run is done on the new dataset with 1830 airfoils, 1 mach #, 25 AoA #s, and 3 Re #s.\n",
    "\n",
    "It runs on the redefined NIF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dbdc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Define autroreload so that it doesn't cause pain in the ass when we change the functions and run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8391a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\SenkDosya\\Projects\\AeroML\n",
      "C:\\SenkDosya\\Projects\\AeroML\\initial-project\n"
     ]
    }
   ],
   "source": [
    "# Import all the models, training functions, manipulators here\n",
    "\n",
    "# Define the relative paths, append it to the system path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().resolve().parents[4]\n",
    "github_root = Path.cwd().resolve().parents[3]\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(str(github_root))\n",
    "\n",
    "print(project_root)\n",
    "print(github_root)\n",
    "\n",
    "# Import shenanigans\n",
    "from defs.helper_functions.training_functions import *\n",
    "from defs.helper_functions.data_loaders import *\n",
    "from defs.models.NIF import *\n",
    "\n",
    "# Time, to precisely: time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bff5cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")  # Force CPU for testing purposes\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ad3c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137250, 27)\n",
      "torch.Size([137250, 20])\n",
      "torch.Size([137250, 3])\n",
      "torch.Size([137250, 3])\n",
      "137250\n"
     ]
    }
   ],
   "source": [
    "# Figure out the data\n",
    "df = pd.read_csv(rf\"C:\\SenkDosya\\Projects\\AeroML\\airfoil_data\\airfoil_dataset_8bern.csv\")\n",
    "\n",
    "df = df.drop(['N1', 'N2'], axis=1) # Remove N1 and N2 since all the airfoils are subsonic\n",
    "\n",
    "df['Reynolds'] = df['Reynolds'] / 100000\n",
    "\n",
    "geom, cond, perf, names= get_dataset(df, loc_geometry=[1,20], loc_cond=[21,23], loc_perf_coeffs=[24,26], loc_names=0) # Get the necessary stuff for the dataset\n",
    "print(df.shape); print(geom.shape); print(cond.shape); print(perf.shape); print(len(names))\n",
    "\n",
    "ds = AirfoilDataset(geom, cond, perf, names)\n",
    "\n",
    "del df, geom, cond, perf, names # Delete these to preserve memory\n",
    "\n",
    "cfg_loader = {\n",
    "    'n_epoch': 100,\n",
    "    'n_train': 1000,\n",
    "    'n_test': 17250,\n",
    "    'train_batch': 1\n",
    "}\n",
    "\n",
    "dl_train, dl_val, dl_test = get_dataloaders(ds=ds, cfg_loader=cfg_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca2fca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model and optimizer\n",
    "\n",
    "cfg_shape_net = {\n",
    "    'input_dim': 20,\n",
    "    'output_dim': 3,\n",
    "    'hidden_units': [2048,2048,2048,2048,2048],\n",
    "    'shape_activation': nn.SELU\n",
    "}\n",
    "\n",
    "cfg_param_net = {\n",
    "    'input_dim': 3,\n",
    "    'hidden_units': [512,512,512],\n",
    "    'param_activation': nn.Tanh\n",
    "}\n",
    "\n",
    "model = NIF_Pointwise(cfg_shape_net=cfg_shape_net, cfg_param_net=cfg_param_net)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss_fn\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4476e9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the model\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Create and move inputs to device\n",
    "show_tensor_1 = torch.randn(5, cfg_shape_net['input_dim']).to(device)\n",
    "show_tensor_2 = torch.randn(5, cfg_param_net['input_dim']).to(device)\n",
    "\n",
    "# Forward pass\n",
    "output = model(show_tensor_1, show_tensor_2)\n",
    "\n",
    "make_dot(output, params=dict(model.named_parameters())).render(\"test\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af13ddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train run 1 loss: 0.7417542338371277\n",
      "Train run 2 loss: 0.7416312098503113\n",
      "Train run 3 loss: 0.7415128946304321\n",
      "Train run 4 loss: 0.7413613200187683\n",
      "Train run 5 loss: 0.7411402463912964\n",
      "Train run 6 loss: 0.7408127784729004\n",
      "Train run 7 loss: 0.7403361201286316\n",
      "Train run 8 loss: 0.7396571040153503\n",
      "Train run 9 loss: 0.7387100458145142\n",
      "Train run 10 loss: 0.7374112010002136\n",
      "Train run 11 loss: 0.7356545925140381\n",
      "Train run 12 loss: 0.7333085536956787\n",
      "Train run 13 loss: 0.7302073240280151\n",
      "Train run 14 loss: 0.7261499166488647\n",
      "Train run 15 loss: 0.7208762168884277\n",
      "Train run 16 loss: 0.7140573263168335\n",
      "Train run 17 loss: 0.7052867412567139\n",
      "Train run 18 loss: 0.6940373778343201\n",
      "Train run 19 loss: 0.6796733736991882\n",
      "Train run 20 loss: 0.6614050269126892\n",
      "Train run 21 loss: 0.6382409334182739\n",
      "Train run 22 loss: 0.6090229749679565\n",
      "Train run 23 loss: 0.5724029541015625\n",
      "Train run 24 loss: 0.5269359350204468\n",
      "Train run 25 loss: 0.4711809754371643\n",
      "Train run 26 loss: 0.4040904641151428\n",
      "Train run 27 loss: 0.3253787159919739\n",
      "Train run 28 loss: 0.2364930361509323\n",
      "Train run 29 loss: 0.14261981844902039\n",
      "Train run 30 loss: 0.056244220584630966\n",
      "Train run 31 loss: 0.003754147095605731\n",
      "Train run 32 loss: 0.025588952004909515\n",
      "Train run 33 loss: 0.09783326089382172\n",
      "Train run 34 loss: 0.11137916892766953\n",
      "Train run 35 loss: 0.07205015420913696\n",
      "Train run 36 loss: 0.029819440096616745\n",
      "Train run 37 loss: 0.0061170607805252075\n",
      "Train run 38 loss: 6.937950092833489e-05\n",
      "Train run 39 loss: 0.004474315792322159\n",
      "Train run 40 loss: 0.012844687327742577\n",
      "Train run 41 loss: 0.020920280367136\n",
      "Train run 42 loss: 0.0264411773532629\n",
      "Train run 43 loss: 0.028546683490276337\n",
      "Train run 44 loss: 0.02728770487010479\n",
      "Train run 45 loss: 0.023293450474739075\n",
      "Train run 46 loss: 0.017564382404088974\n",
      "Train run 47 loss: 0.011299919337034225\n",
      "Train run 48 loss: 0.005721687339246273\n",
      "Train run 49 loss: 0.0018478090642020106\n",
      "Train run 50 loss: 0.0002446481375955045\n",
      "Train run 51 loss: 0.0008040812099352479\n",
      "Train run 52 loss: 0.002717467723414302\n",
      "Train run 53 loss: 0.004762513097375631\n",
      "Train run 54 loss: 0.005848252214491367\n",
      "Train run 55 loss: 0.005511665251106024\n",
      "Train run 56 loss: 0.00404010247439146\n",
      "Train run 57 loss: 0.002180930459871888\n",
      "Train run 58 loss: 0.0006954639102332294\n",
      "Train run 59 loss: 3.514902346068993e-05\n",
      "Train run 60 loss: 0.0002537936088629067\n",
      "Train run 61 loss: 0.001100958208553493\n",
      "Train run 62 loss: 0.0021864832378923893\n",
      "Train run 63 loss: 0.0031323113944381475\n",
      "Train run 64 loss: 0.003672348102554679\n",
      "Train run 65 loss: 0.0036950658541172743\n",
      "Train run 66 loss: 0.0032400377094745636\n",
      "Train run 67 loss: 0.002462520031258464\n",
      "Train run 68 loss: 0.0015775223728269339\n",
      "Train run 69 loss: 0.0007962777162902057\n",
      "Train run 70 loss: 0.0002680568431969732\n",
      "Train run 71 loss: 4.246378011885099e-05\n",
      "Train run 72 loss: 6.57541022519581e-05\n",
      "Train run 73 loss: 0.00021391993504948914\n",
      "Train run 74 loss: 0.000350797432474792\n",
      "Train run 75 loss: 0.0003856367839034647\n",
      "Train run 76 loss: 0.0003039643634110689\n",
      "Train run 77 loss: 0.00015951752720866352\n",
      "Train run 78 loss: 3.681644011521712e-05\n",
      "Train run 79 loss: 6.300710083451122e-06\n",
      "Train run 80 loss: 9.416522516403347e-05\n",
      "Train run 81 loss: 0.00027610675897449255\n",
      "Train run 82 loss: 0.0004927534027956426\n",
      "Train run 83 loss: 0.0006756684742867947\n",
      "Train run 84 loss: 0.000771994236856699\n",
      "Train run 85 loss: 0.00076001335401088\n",
      "Train run 86 loss: 0.0006519510643556714\n",
      "Train run 87 loss: 0.00048531705397181213\n",
      "Train run 88 loss: 0.0003073677944485098\n",
      "Train run 89 loss: 0.00015856626851018518\n",
      "Train run 90 loss: 6.0738748288713396e-05\n",
      "Train run 91 loss: 1.3911940186517313e-05\n",
      "Train run 92 loss: 2.055578079307452e-06\n",
      "Train run 93 loss: 4.2963911255355924e-06\n",
      "Train run 94 loss: 5.942172720097005e-06\n",
      "Train run 95 loss: 4.151158464082982e-06\n",
      "Train run 96 loss: 6.350804142130073e-06\n",
      "Train run 97 loss: 2.3338658138527535e-05\n",
      "Train run 98 loss: 6.144505459815264e-05\n",
      "Train run 99 loss: 0.00011782250658143312\n",
      "Train run 100 loss: 0.0001808491360861808\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Define the configs of train\n",
    "cfg_train = {\n",
    "    'cfg_loader': cfg_loader,\n",
    "    'dtype': torch.float32,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "iter_train = iter(dl_train)\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "batch= next(iter_train)\n",
    "\n",
    "for _ in range(100):\n",
    "    model.train() # Set the model to training mode\n",
    "\n",
    "    shape_input, param_input, target, airfoil_name = batch['geometry'].to(device= device, dtype= dtype), batch['cond'].to(device= device, dtype= dtype), batch['perf_coeffs'].to(device= device, dtype= dtype), batch['name'] \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Get the predictions\n",
    "    pred = model(shape_input= shape_input, param_input= param_input)\n",
    "\n",
    "    # Get the loss \n",
    "    loss = loss_fn(target, pred)\n",
    "    \n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Train run {_+1} loss: {loss}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0bf4d",
   "metadata": {},
   "source": [
    "This confirms model works just fine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pip)",
   "language": "python",
   "name": "pip-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
